# AWS S3

## Buckets
- Buckets are containers for **object** (analogous to files). Buckets are the top-level containers for objects in S3.
- Buckets are created in a specific AWS region.
- Bucket names must be **globally unique**. Most other names in AWS (e.g., IAM users) only need to be regionally unique.
- Buckets can hold an unlimited number of objects (infinitely scalable).

### Specifics
- 3-63 character length for bucket names. Must start with a lowercase letter or number.
- Can't be IP formatted
- **100 buckets soft limit** in an AWS account. You can exceed it with a request to AWS support.
- **1000 buckets hard limit** in an AWS account.

### Objects 
Objects are the files stored in S3.
- The **key** is the unique identifiers for each object in a S3 bucket.
- The **value** is the object's binary data. The value can range from **0B to 5TB** (*exam point*)

### Blast Radius
Bucket data stays within its region unless you allow it to leave the region.

### Bucket Structure
Buckets are flat structures; it is not a file system. All objects are stored at the same level.
- S3 does not use a folder structure, but it **visually** emulates one if `/` characters are used in the object key (e.g., `/old/koala1.png`)

### Hardware
- S3 is an object store. Not a file store or block store.
- It is not a file store (e.g., no folder structure)
- It is not a block store (virtual hard disk) and cannot be mounted as a mount point or volume. Block storage is limited to one user accessing it at a time; S3 does not have this limitation.

### Architecture Choices
S3 should be the default choice for offloading data transfer and access.


## Resource Policies
S3 is private by default.
- S3 **bucket policies** are **resource policies** that govern access.
- Resource policies can allow/deny multiple accounts. 
- Resource policies can allow/deny access to anonymous accounts.
- Resource policies include a `Principal` property in their JSON. It is a distinguishing feature between Resource Policies and Identity Policies. Identity Policies do not need a Principal because they are applied to the relevant Principal (IAM user, IAM group, IAM role, etc.).
- In contrast, Identity Policies can only be attached to an identity in the account. They cannot allow/deny access to other accounts or anonymous accounts.

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicRead",
            "Effect": "Allow",
            "Principal": "*",
            "Action": "s3:*",
            "Resource": "arn:aws:s3:::my-bucket/*"
        }
    ]
}

```

### Conditions
Bucket policies can be configued with conditions to further restrict access, such as the IP address of the requester. MFA can also be required.

### Access Control Lists (ACLs)
ACLs are a legacy method for managing access to S3 resources. ACLs function on objects and buckets. ACLs are not recommended because they are inflexible and only support simple policies. They do not support conditions like bucket policies.

|Permission|Bucket|Object|
|---|---|---|
|Read|Allows grantee to list the objects in the bucket|Allows grantee to read the object data and its metadata|
|Write|Allows grantee to create, overwrite, and delete objects in the bucket|Not applicable|
|Read-ACP|Allows grantee to read the bucket ACL|Allows grantee to read the object ACL|
|Write-ACP|Allows grantee to write the bucket ACL|Allows grantee to write the object ACL|
|Full Control|Allows grantee to READ, WRITE, READ_ACP, and WRITE_ACP on the bucket|Allows grantee to READ, READ_ACP, and WRITE_ACP on the object|

## Block Public Access
Block Public Access is a feature that helps prevent public access to S3 buckets; it was introduced to mitigate incorrect ACL configurations. 

Block Public Access is enabled by default for all new S3 buckets and covers the following:
- Block public access to buckets and objects granted through *new* ACLs
- Block public access to bucket and objects granted through *any* ACLs
- Block public access to bucket and objects granted through *new* bucket policies or access point policies
- Block public access to bucket and objects granted through *any* bucket policies or access point policies

## Permissions Policies
Buckets and objects can be configured via (1) identity policies, (2) resource policies, or (3) ACLs.
- Identity policies are useful for managing different resources, if there is a preference for IAM, or if the policy applies to a single account.
- Bucket policies are useful if managing only S3 or for allowing anonymous or cross-account access.
- ACLs generally should not be used.

## Static Website Hosting
- When creating a new bucket, the bucket policy must allow public read access. This setting technically *allows* you to configure public access to the bucket, but it does not make the contents public itself.
- The bucket policy, under properties -> bucket policy, must then be updated to explicitly allow public read access.
- Static website hosting must be enabled under properties -> static website hosting.

## S3 Versioning

- If versioning is enabled and an object is deleted in non-version-view mode, the object is not deleted. Instead, it is marked as deleted. Deleting the marker fully restores the object.
- If versioning is enabled and an object is deleted in version-view mode, the object is permanently deleted.

## Operations

## PUT (Upload)
S3 objects can be uploaded using either (1) single stream upload or (2) multipart upload. Multipart upload is strongly recommended to avoid failed uploads from disruptions.

- Objects must be smaller than 5GB.
- Multipart upload requires objects to be at least 100MB.
- Maximum number of parts is 10,000.
- Multipart part sizes must be between 5MB and 5GB. 

### S3 Transfer Acceleration
Uploading data to S3 can be slow when the data source is far away from the S3 bucket; public internet routing can be suboptimal. S3 Transfer Acceleration is a feature that speeds up the transfer of files over long distances by using AWS's global network of edge locations to optimize routing.

- Transfer Acceleration is disabled by default. Enabling it has two requirements:
    - Bucket name must be DNS compatible.
    - Bucket name cannot contain periods.

### Encryption
S3 objects can be encrypted client-side or server-side. For client-side encryption, the user must manage the encryption keys and encrypt the data before sending it to S3. 

For server-side encryption, the user can choose the type of encryption and S3 will handle the encryption and decryption. There are three types of server-side encryption for S3 buckets. Symmetric encryption is used for all three.
- **SSE-C**:Customer provided keys
- **SSE-S3**: Amazon S3-managed keys
- **AWS KMS-managed keys** (SSE-KMS)


In SSE-C, the customer sends the plaintext data and a key over HTTPS to AWS. Encryption and decryption are both offloaded to AWS. 
- AWS encrypts the data using the key and stores the resulting ciphertext of the data and a hash of the key. 
- The key is discarded afterwards, but the hash can be used to verify the key if it is used for decrpytion.


In SSE-S3, the customer sends the plaintext data over HTTPS to AWS. 
- AWS generates a plaintext key for each object and encrypts the data using the key. 
- AWS stores the ciphertext and the ciphertext key. The plaintext key is then discarded. 
- SSE-S3 uses AES-256 encryption and handles key rotation.
- SSE-S3 is not suitable for highly regulated industries that require fine grained control over key rotation or role separation (e.g., separating generation of keys from the encryption and decryption of data).

In SSE-KMS, the customer sends the plaintext data over HTTPS to AWS. 
- A KMS Key is used to encrypt the data. The KMS Key can either be (1) a custom KMS Key created by the user or (2) an AWS managed KMS Key.
    - AWS managed KMS Keys can NOT have their key policies or key rotation settings configured.
    - Custom KMS Keys can have their key policies and key rotation settings configured.
- AWS Services that want to encrypt an object using SSE-KMS, will request a new data encryption key (DEK) using a chosen KMS Key. 
- KMS will return a plaintext and ciphertext version of the DEK.
- The plaintext DEK will be used to encrypt the data. The encrypted data and ciphertext DEK are stored in S3. The plaintext DEK is discarded afterwards.

## Storage Classes

### S3 Standard
- Replicated across 3 availability zones (AZs)
    - 99.999999999% durability (11 9s) for 10M objects with an expected loss of 1 object per 10K years
    - MD5 hashes and Cyclic Redundancy Check (CRC) checksums are used to verify data integrity
    - S3's API responds with a **HTTP 1.1/200 OK** status code if an object is stored durably (*exam point*)
- Billing
    - Storage: A GB/month storage fee is charged for data. 
    - Transfer: A $/GB for transfer OUT and a price per 1K requests. Free for transfer IN
- Low latency and high throughput
    - **Millisecond** first byte latency and objects can be made publicly available

### S3 Standard - Infrequent Access (S3 Standard-IA)
- Same replication, durability, and availability behavior as S3 Standard
- Billing
    - Storage: Lower storage costs than S3 Standard. Approximately 1/2 the cost of S3 Standard.
    - Transfer: A $/GB for transfer OUT and a price per 1K requests. Free for transfer IN.
    - Retrieval: A per GB fee for retrieval that is in addition to the transfer fee.
    - Minimum duration charge: A minimum **30 day fee** is charged.
    - Capacity: Standard-IA has a minimum **128KB** object size fee so it should not be used for very small objects.
- Use cases: Use for long-lived data where data access is (1) infrequent and (2) not small.

### S3 One Zone-IA
- Same durability (11 9s) and availability (99.99%) as S3 Standard. 
    - **Only one AZ is used** so if the AZ fails, the data is lost.
    - S3 One-Zone-IA can **NOT** transition to S3 Glacier - Instant Retrieval. It can only transition to S3 Glacier - Flexible Retrieval and S3 Glacier - Deep Archive.
- Same baseline billing as S3 Standard-IA (storage fee,transfer fee, retrieval fee, minimum charge, and minimum capacity fee).
    - Storage fee is lower than S3 Standard-IA because the data is only stored in one AZ.
- Use cases: Use for long-lived data where data access is (1) infrequent, (2) not small, and (3) **non-critical data** (*exam point*) in case the AZ fails.


### S3 Glacier - Instant Retrieval
- Behaves like S3 Standard-IA, but offers cheaper storage while imposing a retrieval fee when data is retrieved.
- Same 3 AZ replication, durability, and availability behavior as S3 Standard
- **Same instant access and public access behavior as S3 Standard-IA.**
- Billing
    - Storage: A GB/month storage fee is charged for data. 
    - Transfer: A $/GB for transfer OUT and a price per 1K requests. Free for transfer IN
    - Retrieval: S3 Glacier does **NOT** have a retrieval process like the other S3 Glacier classes, but it **DOES** impose an additional **retrieval fee** when data is retrieved.
    - Minimum duration charge: A minimum **90 day fee** is charged.
    - Capacity: Standard-IA has a minimum **128KB** object size fee.
- Use cases: Use for archival data where real-time access is not required (e.g., yearly access).
- Use case: Use for data that needs to be instantly accessible, but only occasionally (e.g., quarterly)

### S3 Glacier - Flexible Retrieval
- Same 3 AZ replication, durability, and availability behavior as S3 Standard
- **Cold storage ("chilled state")**
    - Instant access and public access is not supported.
    - S3 Glacier stores a pointer to the data and a **retrieval process** with a **retrieval fee** that must be run to access the data. When retrieved, the data is stored in a S3 Standard-IA bucket temporarily.
- **Retrieval jobs** have a first-byte latency on the order of minutes to hours (faster is more expensive)
    - **Expedited**: 1-5 minutes
    - **Standard**: 3-5 hours
    - **Bulk**: 5-12 hours
- Billing
    - Storage: A GB/month storage fee is charged for data. 
    - Transfer: A $/GB for transfer OUT and a price per 1K requests. Free for transfer IN
    - Retrieval: A per GB fee for retrieval that is in addition to the transfer fee.
    - Minimum duration charge: A minimum **90 day fee** is charged.
    - Capacity: Standard-IA has a minimum **40KB** object size fee.
- Use cases: Use for archival data where real-time access is not required (e.g., yearly access).


### S3 Glacier - Deep Archive
- Same 3 AZ replication, durability, and availability behavior as S3 Standard
- Billing
    - Minimum duration charge: A minimum **180 day fee** is charged.
    - Capacity: Standard-IA has a minimum **40KB** object size fee.
- **Cold storage ("frozen state")**
    - Instant access and public access is not supported.
    - S3 Glacier stores a pointer to the data and a **retrieval process** with a **retrieval fee** that must be run to access the data. When retrieved, the data is stored in a S3 Standard-IA bucket temporarily.
- **Retrieval jobs** have a first-byte latency on the order of hours to days (faster is more expensive)
    - **Standard**: 12 hours
    - **Bulk**: 48 hours
- Use cases: Use for archival purposes where data is almost never accessed (e.g., audits). It should not be used for primary system backup or restoration purposes.

### S3 Intelligent-Tiering
S3 Intelligent-Tiering monitors usage patterns and automatically moves objects between tiers to optimize costs and performance.
- Contains 5 different storage tiers:
    - **Frequent Access**: Like S3 Standard
    - **Infrequent Access**: Like S3 Standard-IA
    - **Archive Instant Access**: Same as S3 Glacier - Instant Retrieval
    - **Archive Access**: Same as S3 Glacier - Flexible Retrieval
    - **Deep Archive Access**: Same as S3 Glacier - Deep Archive
- **Behavior**: Any object that is not accessed after a set period of time is moved to the next tier.
    - **30 days**: Object is moved to the **Infrequent Access** tier 
    - **90 days**: Object is moved to the **Archive Instant Access** tier
        - Note: There is no minimum duration charge for Archive Instant Access.
    - **90-270 days** (configurable optional tier): Object is moved to the **Archive Access** tier
    - **180-730 days** (configurable optional tier): Object is moved to the **Deep Archive Access** tier
- **Billing**:
    - Data is automatically moved up to the next tier if it is accessed **without a retrieval charge**.
    - A **monitoring and automation fee (management fee)** is charged per 1000 objects per month.
- Use case: Use for long-lived data with unknown access patterns. Implement the Archive Access and Deep Archive Access tiers only if the application can support them since API calls are needed to move objects between tiers.

## Lifecycle Configuration
A lifecycle is a **set of rules** that consist of **actions** on a **bucket** or **groups of objects in a bucket**.

### Types of Actions
- **Transition**: Moves objects between storage classes (e.g., S3 Standard to S3 Standard-IA after 30 days).
- **Expiration**: Deletes objects after a specified period of time (e.g., delete objects or object versionsafter 100 days).


### Lifecycle Transition Rules
Objects can be transitioned to a colder storage class roughly following a waterfall model. Each class can transition to **any** class below it. The only exception is S3 One Zone-IA, which can **NOT** transition to S3 Glacier - Instant Retrieval. It can only transition to S3 Glacier - Flexible Retrieval and S3 Glacier - Deep Archive.

```
- S3 Standard
  - S3 Standard-IA
    - S3 Intelligent-Tiering
      - S3 One Zone-IA
        - S3 Glacier - Instant Retrieval
          - S3 Glacier - Flexible Retrieval
            - S3 Glacier - Deep Archive
```

#### S3 Standard Object Special Rules
- S3 Standard objects must remain there for at least 30 days before they can transition to S3 Standard-IA or S3 One Zone-IA (*exam point*). 
    - Objects can be loaded directly into S3 Standard-IA or S3 One Zone-IA, but must wait if they started in S3 Standard.
    - A single rule cannot be configured to automatically transition an S3 Standard object first to S3 Standard-IA or S3 One Zone-IA and then to a glacier class in under the 30 day minimum. If can be done by 2 rules
- If a single rule is used to transition S3 objects to S3 Standard-IA or S3 One Zone-IA and then to a glacier class, an additional 30 days waiting period is required before the second transition.
    - The second 30 day waiting period can be avoided by using 2 rules.

## Replication
There are two types of replication:
- **S3 Same-Region Replication (SRR)**
- **S3 Cross-Region Replication (CRR)**

The difference between SRR and CRR is only whether the buckets are in the same AWS account or different AWS accounts.

### Replication Configuration
- Replication is applied to the **source bucket** and specifies which **destination bucket** to replicate to.
- Replication is encrypted over SSL.
- **Requirements**:
    - An **IAM Role** for the replication process must be configured to allow S3 to assume it for the replication process. It must have permission to read objects from the source bucket and write objects to the destination bucket.
    - If the destination bucket is in a different AWS Account, a **bucket policy** (resource policy) must be applied to **trust** the IAM Role so it can write to the destination bucket.
    - Source bucket owner must have permission to read objects from the source bucket. This assumption might be violated if other accounts were given permission to add objects to the source bucket.
    - **Versioning**: Versioning must be enabled on both the source and destination buckets. It can be enabled if it not currently enabled (*exam point*).

### Replication Options
    - **Data Subset**: All objects are replicated by default. A subset of objects can be replicated by specifying a combination of **prefix** or **tags** in the replication configuration.
    - **Storage Class**: The default is to use the same storage class between the source and destination buckets. The destination bucket can be configured to use a different storage class (*exam point*).
    - **Ownership**: The default for the destination bucket is to inherit the ownership of the source bucket if they are in the same AWS Account. If they are in different AWS Accounts, the destination account may not be able to read the objects in the destination bucket; the owner can be overridden in the replication configuration.
    - **Replication Time Control (RTC)**: RTC can be enabled to ensure that objects are replicated with a maximum of 15 minutes of delay (*exam point*). If it is not enabled, the replication process is on a best effort basis.
- **Not Retroactive**: Replication is **NOT** retroactive (*exam point*). Only new objects are replicated. Existing objects are not replicated.
- **One-Way Replication**: Replication is **one-way** (*exam point*). Objects are not replicated back to the source bucket. Recently, AWS added bi-directional replication, but it is an additional setting that requires configuration.
- **Encryption**: Objects that are unencrypted, SSE-S3, and SSE-KMS are replicated. Support for SSE-C was recently added.
- **System Events**: Lifecycle system events are not replicated (e.g., deletion marker from a lifecycle event or notification settings from a lifecycle event). 
- **Storage Class**: Glacier and Glacier Deep Archive objects can not be replicated.
- **Delete Marker**: Delete markers are not replicated unless **DeleteMarkerReplication** is enabled in the replication configuration.

### Replication Use Cases

SRR: Log aggregation, syncing TEST and PROD, Resilience with strict sovereignty requirements

CRR: Global resilience and latency reduction